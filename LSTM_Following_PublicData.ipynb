{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import read_csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a 'look back' dataset for sequence to label prediction with Keras.\n",
    "\n",
    "# The LSTM network expects the input data (X) to be provided with a specific\n",
    "# array structure in the form of: [samples, time steps, features].\n",
    "\n",
    "def create_dataset(X, Y, **options):\n",
    "    \"\"\"Convert an array of X, Y values into a dataset matrix for and LSTM\"\"\"\n",
    "    \n",
    "    look_back = options.pop('look_back', None)\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(X) - look_back):\n",
    "        a = X[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(Y[i + look_back - 1])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# Predictions will be based on look_back minutes of data:\n",
    "look_back = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_path = glob.glob('../XiaofengWang/TrafficNet/Test_Following_TrafficNet/*.csv')\n",
    "\n",
    "X_TestData = np.empty((1, 50, 28))\n",
    "Y_TestData = np.empty((1,))\n",
    "\n",
    "for f in range(300):\n",
    "    print(Test_path[f].split('/')[-1])\n",
    "    \n",
    "    Following_Test = pd.read_csv(Test_path[f], usecols=['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','AxWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','Following','o1','o2','o3','r1','r2','r3','rr1','rr2','rr3','t1','t2','t3','tt1','tt2','tt3','tt5','c1','c2','c3'])\n",
    "    \n",
    "    Following_Test.fillna(10000000, inplace=True)\n",
    "    \n",
    "    Y_train_Test = np.array(Following_Test['Following'].values)\n",
    "    X_train_Test = np.array(Following_Test[['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','AxWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','o1','o2','o3','r1','r2','r3','rr1','rr2','rr3','t1','t2','t3','tt1','tt2','tt3','tt5','c1','c2','c3']])\n",
    "\n",
    "    dimof_output = 1\n",
    "    dimof_input = X_train_Test.shape[1]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_Test = scaler.fit_transform(X_train_Test)\n",
    "    \n",
    "    XTest, YTest = create_dataset(X_train_Test, Y_train_Test, look_back=look_back)\n",
    "    \n",
    "    X_TestData = np.append(X_TestData, XTest, axis=0)\n",
    "    Y_TestData = np.append(Y_TestData, YTest, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_path = glob.glob('../XiaofengWang/TrafficNet/Train_Following_TrafficNet/*.csv')\n",
    "\n",
    "X_all = np.empty((1, 50, 28))\n",
    "Y_all = np.empty((1,))\n",
    "\n",
    "for j in range(400):\n",
    "    Following = pd.read_csv(Train_path[j], usecols=['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','AxWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','Following','o1','o2','o3','r1','r2','r3','rr1','rr2','rr3','t1','t2','t3','tt1','tt2','tt3','tt5','c1','c2','c3'])\n",
    "    \n",
    "    Following.fillna(10000000, inplace=True)\n",
    "    \n",
    "    Y_train = np.array(Following['Following'].values)\n",
    "    X_train = np.array(Following[['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','AxWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','o1','o2','o3','r1','r2','r3','rr1','rr2','rr3','t1','t2','t3','tt1','tt2','tt3','tt5','c1','c2','c3']])\n",
    "\n",
    "    dimof_output = 1\n",
    "    dimof_input = X_train.shape[1]\n",
    "\n",
    "    # Scale/whiten the X data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    \n",
    "    X, Y = create_dataset(X_train, Y_train, look_back=look_back)\n",
    "    \n",
    "    X_all = np.append(X_all, X, axis=0)\n",
    "    Y_all = np.append(Y_all, Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These sizes need to be divisible by 32 and remove the first randomly created matrix.\n",
    "Train_size = len(X_all)//64*64 + 1\n",
    "Test_size = len(X_TestData)//64*64 + 1\n",
    "\n",
    "Xtest = X_TestData[1:Test_size]\n",
    "Ytest = Y_TestData[1:Test_size]\n",
    "\n",
    "Xtrain = X_all[1:Train_size]\n",
    "Ytrain = Y_all[1:Train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM network.\n",
    "batch_size = 32\n",
    "dropout = 0.5\n",
    "num_epoch = 100\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "weights = {0:1, 1:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Following = Sequential()\n",
    "Following.add(LSTM(output_dim=10, batch_input_shape=[batch_size, look_back, dimof_input]))\n",
    "Following.add(Dropout(dropout))\n",
    "Following.add(Dense(30, activation='relu'))\n",
    "Following.add(Dropout(dropout))\n",
    "Following.add(Dense(dimof_output, init='uniform', activation='sigmoid'))\n",
    "Following.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = Following.fit(\n",
    "    Xtrain, Ytrain,\n",
    "    class_weight=weights,\n",
    "    validation_data=(Xtest, Ytest),\n",
    "    callbacks=[earlyStopping],\n",
    "    shuffle=True,\n",
    "    nb_epoch=num_epoch, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print(history.history)\n",
    "\n",
    "Y_predict = model_CutIn.predict_classes(Xtest, verbose=True)\n",
    "\n",
    "# Add the prediction in a list\n",
    "a6 = Y_predict.tolist()\n",
    "# item[0] of the prediction is the predicted label\n",
    "a26 = [item[0] for item in a6]\n",
    "# the true label\n",
    "b6 = Ytest.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_predict = [index for index, element in enumerate(a26) if element == 1]\n",
    "p = sum((list(t) for t in zip(nums_predict, nums_predict[1:]) if t[0]+1 != t[1]), [])\n",
    "p.insert(0,nums_predict[0])\n",
    "p.append(nums_predict[-1])\n",
    "\n",
    "nums_Y = [index for index, element in enumerate(b6) if element == 1]\n",
    "y = sum((list(t) for t in zip(nums_Y, nums_Y[1:]) if t[0]+1 != t[1]), [])\n",
    "y.insert(0,nums_Y[0])\n",
    "y.append(nums_Y[-1])\n",
    "\n",
    "big=0\n",
    "small=0\n",
    "same=0\n",
    "\n",
    "for i in range(len(y)-1):\n",
    "    if i % 2 == 0:\n",
    "        for j in range(len(p)):\n",
    "            if j % 2 == 0: \n",
    "\n",
    "                if (y[i] == p[j]) and (y[i+1] == p[j+1]):\n",
    "                    same=same+1\n",
    "                    j=j+2\n",
    "                \n",
    "                elif p[j]<=y[i] and p[j+1]>=y[i+1]:\n",
    "                    big=big+1\n",
    "                    j=j+2\n",
    "                        \n",
    "                elif p[j]>=y[i] and p[j+1]<=y[i+1]:\n",
    "                    small=small+1\n",
    "                    j=j+2\n",
    "                    \n",
    "                else:\n",
    "                    j=j+2       \n",
    "        i=i+2    \n",
    "\n",
    "Predict = len(p)/2\n",
    "Y = len(y)/2\n",
    "\n",
    "def precision(n):\n",
    "    fp = Predict-n\n",
    "    prec = n/(n+fp)\n",
    "    if prec >=1:\n",
    "        b=1\n",
    "    else:\n",
    "        b=prec\n",
    "    return b\n",
    "\n",
    "def recall(n):\n",
    "    fn = Y-n\n",
    "    rec = n/(n+fn)\n",
    "    if rec >=1:\n",
    "        a=1\n",
    "    else:\n",
    "        a=rec\n",
    "    return a\n",
    "    \n",
    "def conf(f):\n",
    "    conf95 = []\n",
    "    for i in range(len(y)):\n",
    "        if i%2 == 0:\n",
    "            c951=int(y[i]-f*(y[i+1]-y[i]))\n",
    "            conf95.append(c951)\n",
    "            conf95.append(y[i+1])\n",
    "        \n",
    "            c9522=y[i]+f*(y[i+1]-y[i])\n",
    "            if float(c9522).is_integer()==True:\n",
    "                conf95.append(c9522)\n",
    "                conf95.append(y[i+1])\n",
    "            else:\n",
    "                con952 = int(c9522)+1\n",
    "                conf95.append(con952)\n",
    "                conf95.append(y[i+1])\n",
    "        \n",
    "            conf95.append(y[i])\n",
    "            c9533=int(y[i+1]-f*(y[i+1]-y[i]))\n",
    "            if float(c9533).is_integer()==True:\n",
    "                conf95.append(c9533)\n",
    "            else:\n",
    "                c953 = int(c9533)+1\n",
    "                conf95.append(c953)\n",
    "            \n",
    "            conf95.append(y[i])    \n",
    "            c9544=y[i+1]+f*(y[i+1]-y[i])\n",
    "            if float(c9544).is_integer()==True:\n",
    "                conf95.append(c9544)\n",
    "            else:\n",
    "                con954 = int(c9544)+1\n",
    "                conf95.append(con954)\n",
    "        i=i+2\n",
    "    return conf95\n",
    "\n",
    "def result(rangelist):\n",
    "    con95=0\n",
    "    for i in range(len(p)):\n",
    "        if i%2 == 0:\n",
    "            for j in range(len(rangelist)-7):\n",
    "                if j%8==0:\n",
    "                    if (rangelist[j]<=p[i] and p[i+1]<=rangelist[j+1]) or (rangelist[j+2]<=p[i] and p[i+1]<=rangelist[j+3]) or (rangelist[j+4]<=p[i] and p[i+1]<=rangelist[j+5]) or (rangelist[j+6]<=p[i] and p[i+1]<=rangelist[j+7]):       \n",
    "                        con95=con95+1\n",
    "                        break\n",
    "                    else:\n",
    "                        j=j+8\n",
    "            i=i+2\n",
    "    return con95   \n",
    "\n",
    "con95 = result(conf(0.05))\n",
    "con90 = result(conf(0.1))          \n",
    "con85 = result(conf(0.15))            \n",
    "con80 = result(conf(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predict:\", Predict, \"-\", \"True:\", Y)   \n",
    "print(\"big:\",big, \"-\", \"precision:\", precision(big), \"-\", \"recall:\", recall(big))  \n",
    "print(\"small:\",small, \"-\", \"precision:\", precision(small), \"-\", \"recall:\", recall(small)) \n",
    "print(\"same:\",same, \"-\", \"precision:\", precision(same), \"-\", \"recall:\", recall(same)) \n",
    "print(\"con95:\",con95, \"-\", \"precision:\", precision(con95), \"-\", \"recall:\", recall(con95))  \n",
    "print(\"con90:\",con90, \"-\", \"precision:\", precision(con90), \"-\", \"recall:\", recall(con90)) \n",
    "print(\"con85:\",con85, \"-\", \"precision:\", precision(con85), \"-\", \"recall:\", recall(con85)) \n",
    "print(\"con80:\",con80, \"-\", \"precision:\", precision(con80), \"-\", \"recall:\", recall(con80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_MoreTrainData = np.empty((1, 50, 28))\n",
    "Y_MoreTrainData = np.empty((1,))\n",
    "\n",
    "for j in range(500,1000):\n",
    "    \n",
    "    Following_more = pd.read_csv(Train_path[j], usecols=['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','AxWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','Following','o1','o2','o3','r1','r2','r3','rr1','rr2','rr3','t1','t2','t3','tt1','tt2','tt3','tt5','c1','c2','c3'])\n",
    "    if Following_more.shape[0] <= 50:\n",
    "        pass\n",
    "    else:\n",
    "        Following_more.fillna(10000000, inplace=True)\n",
    "    \n",
    "        Y_train_more = np.array(Following_more['Following'].values)\n",
    "        X_train_more = np.array(Following_more[['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','AxWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','o1','o2','o3','r1','r2','r3','rr1','rr2','rr3','t1','t2','t3','tt1','tt2','tt3','tt5','c1','c2','c3']])\n",
    "\n",
    "        # Scale/whiten the X data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_more = scaler.fit_transform(X_train_more)\n",
    "    \n",
    "        X_more, Y_more = create_dataset(X_train_more, Y_train_more, look_back=look_back)\n",
    "    \n",
    "        X_MoreTrainData = np.append(X_MoreTrainData, X_more, axis=0)\n",
    "        Y_MoreTrainData = np.append(Y_MoreTrainData, Y_more, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added_size need to be divisible by 32 and remove the first randomly created matrix.\n",
    "Added_size = len(X_MoreTrainData)//64*64+1\n",
    "\n",
    "X_MoreTrainData = X_MoreTrainData[1:Added_size]\n",
    "Y_MoreTrainData = Y_MoreTrainData[1:Added_size]\n",
    "\n",
    "Xtrain = np.append(Xtrain, X_MoreTrainData, axis=0)\n",
    "Ytrain = np.append(Ytrain, Y_MoreTrainData, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\XWANG221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XWANG221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(batch_input_shape=[32, 50, 2..., units=20)`\n",
      "  \n",
      "C:\\Users\\XWANG221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\XWANG221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\XWANG221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 35968 samples, validate on 27840 samples\n",
      "Epoch 1/100\n",
      "35968/35968 [==============================] - 19s 524us/step - loss: 0.5835 - accuracy: 0.6832 - val_loss: 0.5880 - val_accuracy: 0.7031\n",
      "Epoch 2/100\n",
      "35968/35968 [==============================] - 19s 535us/step - loss: 0.4345 - accuracy: 0.8057 - val_loss: 0.5829 - val_accuracy: 0.7338\n",
      "Epoch 3/100\n",
      "35968/35968 [==============================] - 19s 515us/step - loss: 0.3803 - accuracy: 0.8411 - val_loss: 0.5383 - val_accuracy: 0.7571\n",
      "Epoch 4/100\n",
      "35968/35968 [==============================] - 19s 516us/step - loss: 0.3563 - accuracy: 0.8506 - val_loss: 0.5522 - val_accuracy: 0.7688\n",
      "{'val_loss': [0.587972610182632, 0.5828519457212553, 0.5382926730139331, 0.5521831452589611], 'val_accuracy': [0.703125, 0.7338002920150757, 0.7571479678153992, 0.7688218355178833], 'loss': [0.5835399936049435, 0.43450437873283737, 0.3802782566787085, 0.3563428303472088], 'accuracy': [0.6831628, 0.805744, 0.84108096, 0.8505894]}\n",
      "27840/27840 [==============================] - 4s 152us/step\n"
     ]
    }
   ],
   "source": [
    "Following = Sequential()\n",
    "Following.add(LSTM(output_dim=10, batch_input_shape=[batch_size, look_back, dimof_input]))\n",
    "Following.add(Dropout(dropout))\n",
    "Following.add(Dense(30, activation='relu'))\n",
    "Following.add(Dropout(dropout))\n",
    "Following.add(Dense(dimof_output, init='uniform', activation='sigmoid'))\n",
    "Following.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = Following.fit(\n",
    "    Xtrain, Ytrain,\n",
    "    class_weight=weights,\n",
    "    validation_data=(Xtest, Ytest),\n",
    "    callbacks=[earlyStopping],\n",
    "    shuffle=True,\n",
    "    nb_epoch=num_epoch, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print(history.history)\n",
    "\n",
    "Y_predict = model_CutIn.predict_classes(Xtest, verbose=True)\n",
    "\n",
    "# Add the prediction in a list\n",
    "a6 = Y_predict.tolist()\n",
    "# item[0] of the prediction is the predicted label\n",
    "a26 = [item[0] for item in a6]\n",
    "# the true label\n",
    "b6 = Ytest.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_predict = [index for index, element in enumerate(a26) if element == 1]\n",
    "p = sum((list(t) for t in zip(nums_predict, nums_predict[1:]) if t[0]+1 != t[1]), [])\n",
    "p.insert(0,nums_predict[0])\n",
    "p.append(nums_predict[-1])\n",
    "\n",
    "nums_Y = [index for index, element in enumerate(b6) if element == 1]\n",
    "y = sum((list(t) for t in zip(nums_Y, nums_Y[1:]) if t[0]+1 != t[1]), [])\n",
    "y.insert(0,nums_Y[0])\n",
    "y.append(nums_Y[-1])\n",
    "\n",
    "big=0\n",
    "small=0\n",
    "same=0\n",
    "\n",
    "for i in range(len(y)-1):\n",
    "    if i % 2 == 0:\n",
    "        for j in range(len(p)):\n",
    "            if j % 2 == 0: \n",
    "\n",
    "                if (y[i] == p[j]) and (y[i+1] == p[j+1]):\n",
    "                    same=same+1\n",
    "                    j=j+2\n",
    "                \n",
    "                elif p[j]<=y[i] and p[j+1]>=y[i+1]:\n",
    "                    big=big+1\n",
    "                    j=j+2\n",
    "                        \n",
    "                elif p[j]>=y[i] and p[j+1]<=y[i+1]:\n",
    "                    small=small+1\n",
    "                    j=j+2\n",
    "                    \n",
    "                else:\n",
    "                    j=j+2       \n",
    "        i=i+2    \n",
    "\n",
    "Predict = len(p)/2\n",
    "Y = len(y)/2\n",
    "\n",
    "def precision(n):\n",
    "    fp = Predict-n\n",
    "    prec = n/(n+fp)\n",
    "    if prec >=1:\n",
    "        b=1\n",
    "    else:\n",
    "        b=prec\n",
    "    return b\n",
    "\n",
    "def recall(n):\n",
    "    fn = Y-n\n",
    "    rec = n/(n+fn)\n",
    "    if rec >=1:\n",
    "        a=1\n",
    "    else:\n",
    "        a=rec\n",
    "    return a\n",
    "    \n",
    "def conf(f):\n",
    "    conf95 = []\n",
    "    for i in range(len(y)):\n",
    "        if i%2 == 0:\n",
    "            c951=int(y[i]-f*(y[i+1]-y[i]))\n",
    "            conf95.append(c951)\n",
    "            conf95.append(y[i+1])\n",
    "        \n",
    "            c9522=y[i]+f*(y[i+1]-y[i])\n",
    "            if float(c9522).is_integer()==True:\n",
    "                conf95.append(c9522)\n",
    "                conf95.append(y[i+1])\n",
    "            else:\n",
    "                con952 = int(c9522)+1\n",
    "                conf95.append(con952)\n",
    "                conf95.append(y[i+1])\n",
    "        \n",
    "            conf95.append(y[i])\n",
    "            c9533=int(y[i+1]-f*(y[i+1]-y[i]))\n",
    "            if float(c9533).is_integer()==True:\n",
    "                conf95.append(c9533)\n",
    "            else:\n",
    "                c953 = int(c9533)+1\n",
    "                conf95.append(c953)\n",
    "            \n",
    "            conf95.append(y[i])    \n",
    "            c9544=y[i+1]+f*(y[i+1]-y[i])\n",
    "            if float(c9544).is_integer()==True:\n",
    "                conf95.append(c9544)\n",
    "            else:\n",
    "                con954 = int(c9544)+1\n",
    "                conf95.append(con954)\n",
    "        i=i+2\n",
    "    return conf95\n",
    "\n",
    "def result(rangelist):\n",
    "    con95=0\n",
    "    for i in range(len(p)):\n",
    "        if i%2 == 0:\n",
    "            for j in range(len(rangelist)-7):\n",
    "                if j%8==0:\n",
    "                    if (rangelist[j]<=p[i] and p[i+1]<=rangelist[j+1]) or (rangelist[j+2]<=p[i] and p[i+1]<=rangelist[j+3]) or (rangelist[j+4]<=p[i] and p[i+1]<=rangelist[j+5]) or (rangelist[j+6]<=p[i] and p[i+1]<=rangelist[j+7]):       \n",
    "                        con95=con95+1\n",
    "                        break\n",
    "                    else:\n",
    "                        j=j+8\n",
    "            i=i+2\n",
    "    return con95   \n",
    "\n",
    "con95 = result(conf(0.05))\n",
    "con90 = result(conf(0.1))          \n",
    "con85 = result(conf(0.15))            \n",
    "con80 = result(conf(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: 420.0 - True: 422.0\n",
      "big: 204 - precision: 0.4857142857142857 - recall: 0.4834123222748815\n",
      "small: 67 - precision: 0.1595238095238095 - recall: 0.15876777251184834\n",
      "same: 0 - precision: 0.0 - recall: 0.0\n",
      "con95: 94 - precision: 0.22380952380952382 - recall: 0.22274881516587677\n",
      "con90: 117 - precision: 0.2785714285714286 - recall: 0.2772511848341232\n",
      "con85: 143 - precision: 0.3404761904761905 - recall: 0.33886255924170616\n",
      "con80: 154 - precision: 0.36666666666666664 - recall: 0.36492890995260663\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict:\", Predict, \"-\", \"True:\", Y)   \n",
    "print(\"big:\",big, \"-\", \"precision:\", precision(big), \"-\", \"recall:\", recall(big))  \n",
    "print(\"small:\",small, \"-\", \"precision:\", precision(small), \"-\", \"recall:\", recall(small)) \n",
    "print(\"same:\",same, \"-\", \"precision:\", precision(same), \"-\", \"recall:\", recall(same)) \n",
    "print(\"con95:\",con95, \"-\", \"precision:\", precision(con95), \"-\", \"recall:\", recall(con95))  \n",
    "print(\"con90:\",con90, \"-\", \"precision:\", precision(con90), \"-\", \"recall:\", recall(con90)) \n",
    "print(\"con85:\",con85, \"-\", \"precision:\", precision(con85), \"-\", \"recall:\", recall(con85)) \n",
    "print(\"con80:\",con80, \"-\", \"precision:\", precision(con80), \"-\", \"recall:\", recall(con80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
