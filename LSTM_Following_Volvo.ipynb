{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import read_csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a 'look back' dataset for sequence to label prediction with Keras.\n",
    "\n",
    "# The LSTM network expects the input data (X) to be provided with a specific\n",
    "# array structure in the form of: [samples, time steps, features].\n",
    "\n",
    "# create_dataset is adapted from\n",
    "# http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "def create_dataset(X, Y, **options):\n",
    "    \"\"\"Convert an array of X, Y values into a dataset matrix for and LSTM\"\"\"\n",
    "    \n",
    "    look_back = options.pop('look_back', None)\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(X) - look_back):\n",
    "        a = X[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(Y[i + look_back - 1])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# Predictions will be based on look_back minutes of data:\n",
    "look_back = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test1 = glob.glob('../TrafficNet/Required/Test_Following/*.csv')\n",
    "\n",
    "X_Test1 = np.empty((1, 50, 59))\n",
    "Y_Test1 = np.empty((1,))\n",
    "\n",
    "for f in range(300):\n",
    "    print(Test1[f].split('/')[-1])\n",
    "    \n",
    "    Following_Test1 = pd.read_csv(Test1[f], usecols=['Lat','Long','InReverse','Lane','PositionInLane','Velocity','PosLgt1','PosLgt2','PosLgt3','PosLgt4','PosLgt5','PosLat1','PosLat2','PosLat3','PosLat4','PosLat5','VelLgt1','VelLgt2','VelLgt3','VelLgt4','VelLgt5','VelLat1','VelLat2','VelLat3','VelLat4','VelLat5','AccLgt1','AccLgt2','AccLgt3','AccLgt4','AccLgt5','AccLat1','AccLat2','AccLat3','AccLat4','AccLat5','Angle1','Angle2','Angle3','Angle4','Angle5','Type1','Type2','Type3','Type4','Type5','Id1','Id2','Id3','Id4','Id5','Lane1','Lane2','Lane3','Lane4','PositionInLane1','PositionInLane2','PositionInLane3','PositionInLane4','Lead','Following'])  \n",
    "    Following_Test1.fillna(10000000, inplace=True)\n",
    "    \n",
    "    Y_train_Test1 = np.array(Following_Test1['Following'].values)\n",
    "    X_train_Test1 = np.array(Following_Test1[['Lat','Long','InReverse','Lane','PositionInLane','Velocity','PosLgt1','PosLgt2','PosLgt3','PosLgt4','PosLgt5','PosLat1','PosLat2','PosLat3','PosLat4','VelLgt1','VelLgt2','VelLgt3','VelLgt4','VelLgt5','VelLat1','VelLat2','VelLat3','VelLat4','VelLat5','AccLgt1','AccLgt2','AccLgt3','AccLgt4','AccLgt5','AccLat1','AccLat2','AccLat3','AccLat4','AccLat5','Angle1','Angle2','Angle3','Angle4','Angle5','Type1','Type2','Type3','Type4','Type5','Id1','Id2','Id3','Id4','Id5','Lane1','Lane2','Lane3','Lane4','PositionInLane1','PositionInLane2','PositionInLane3','PositionInLane4','Lead']])\n",
    "    \n",
    "    # Get dimensions of input and output\n",
    "    #dimof_output = int(np.max(Y_train) + 1)\n",
    "    dimof_output = 1\n",
    "    dimof_input = X_train_Test1.shape[1]\n",
    "\n",
    "    # Scale/whiten the X data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_Test1 = scaler.fit_transform(X_train_Test1)\n",
    "    #print(len(X_train))\n",
    "    #print(X_train_Test1.shape, Y_train_Test1.shape)\n",
    "    \n",
    "    XTest1, YTest1 = create_dataset(X_train_Test1, Y_train_Test1, look_back=look_back)\n",
    "    #print(XTest1.shape, YTest1.shape)\n",
    "    \n",
    "    X_Test1 = np.append(X_Test1, XTest1, axis=0)\n",
    "    Y_Test1 = np.append(Y_Test1, YTest1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.glob('../TrafficNet/Required/Train_Following/*.csv')\n",
    "\n",
    "X_all = np.empty((1, 50, 59))\n",
    "Y_all = np.empty((1,))\n",
    "\n",
    "for j in range(50):\n",
    "    #print(j)\n",
    "    Following = pd.read_csv(path[j], usecols=['Lat','Long','InReverse','Lane','PositionInLane','Velocity','PosLgt1','PosLgt2','PosLgt3','PosLgt4','PosLgt5','PosLat1','PosLat2','PosLat3','PosLat4','PosLat5','VelLgt1','VelLgt2','VelLgt3','VelLgt4','VelLgt5','VelLat1','VelLat2','VelLat3','VelLat4','VelLat5','AccLgt1','AccLgt2','AccLgt3','AccLgt4','AccLgt5','AccLat1','AccLat2','AccLat3','AccLat4','AccLat5','Angle1','Angle2','Angle3','Angle4','Angle5','Type1','Type2','Type3','Type4','Type5','Id1','Id2','Id3','Id4','Id5','Lane1','Lane2','Lane3','Lane4','PositionInLane1','PositionInLane2','PositionInLane3','PositionInLane4','Lead','Following'])  \n",
    "    Following.fillna(10000000, inplace=True)\n",
    "    \n",
    "    Y_train = np.array(Following['Following'].values)\n",
    "    X_train = np.array(Following[['Lat','Long','InReverse','Lane','PositionInLane','Velocity','PosLgt1','PosLgt2','PosLgt3','PosLgt4','PosLgt5','PosLat1','PosLat2','PosLat3','PosLat4','VelLgt1','VelLgt2','VelLgt3','VelLgt4','VelLgt5','VelLat1','VelLat2','VelLat3','VelLat4','VelLat5','AccLgt1','AccLgt2','AccLgt3','AccLgt4','AccLgt5','AccLat1','AccLat2','AccLat3','AccLat4','AccLat5','Angle1','Angle2','Angle3','Angle4','Angle5','Type1','Type2','Type3','Type4','Type5','Id1','Id2','Id3','Id4','Id5','Lane1','Lane2','Lane3','Lane4','PositionInLane1','PositionInLane2','PositionInLane3','PositionInLane4','Lead']])\n",
    "    \n",
    "    # Get dimensions of input and output\n",
    "    #dimof_output = int(np.max(Y_train) + 1)\n",
    "    dimof_output = 1\n",
    "    dimof_input = X_train.shape[1]\n",
    "\n",
    "    # Scale/whiten the X data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    #print(len(X_train))\n",
    "    #print(X_train.shape, Y_train.shape)\n",
    "    \n",
    "    X, Y = create_dataset(X_train, Y_train, look_back=look_back)\n",
    "    #print(X.shape, Y.shape)\n",
    "    \n",
    "    X_all = np.append(X_all, X, axis=0)\n",
    "    Y_all = np.append(Y_all, Y, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_all5 = np.empty((1, 50, 59))\n",
    "Y_all5 = np.empty((1,))\n",
    "\n",
    "for j in range(500,1000):\n",
    "    #print(j)\n",
    "    \n",
    "    Following5 = pd.read_csv(path[j], usecols=['Lat','Long','InReverse','Lane','PositionInLane','Velocity','PosLgt1','PosLgt2','PosLgt3','PosLgt4','PosLgt5','PosLat1','PosLat2','PosLat3','PosLat4','PosLat5','VelLgt1','VelLgt2','VelLgt3','VelLgt4','VelLgt5','VelLat1','VelLat2','VelLat3','VelLat4','VelLat5','AccLgt1','AccLgt2','AccLgt3','AccLgt4','AccLgt5','AccLat1','AccLat2','AccLat3','AccLat4','AccLat5','Angle1','Angle2','Angle3','Angle4','Angle5','Type1','Type2','Type3','Type4','Type5','Id1','Id2','Id3','Id4','Id5','Lane1','Lane2','Lane3','Lane4','PositionInLane1','PositionInLane2','PositionInLane3','PositionInLane4','Lead','Following'])  \n",
    "    if Following5.shape[0] <= 50:\n",
    "        pass\n",
    "    else:\n",
    "        Following5.fillna(10000000, inplace=True)\n",
    "    \n",
    "        Y_train5 = np.array(Following5['Following'].values)\n",
    "        X_train5 = np.array(Following5[['Lat','Long','InReverse','Lane','PositionInLane','Velocity','PosLgt1','PosLgt2','PosLgt3','PosLgt4','PosLgt5','PosLat1','PosLat2','PosLat3','PosLat4','VelLgt1','VelLgt2','VelLgt3','VelLgt4','VelLgt5','VelLat1','VelLat2','VelLat3','VelLat4','VelLat5','AccLgt1','AccLgt2','AccLgt3','AccLgt4','AccLgt5','AccLat1','AccLat2','AccLat3','AccLat4','AccLat5','Angle1','Angle2','Angle3','Angle4','Angle5','Type1','Type2','Type3','Type4','Type5','Id1','Id2','Id3','Id4','Id5','Lane1','Lane2','Lane3','Lane4','PositionInLane1','PositionInLane2','PositionInLane3','PositionInLane4','Lead']])\n",
    "    \n",
    "    # Scale/whiten the X data\n",
    "        scaler = StandardScaler()\n",
    "        X_train5 = scaler.fit_transform(X_train5)\n",
    "    #print(len(X_train))\n",
    "    #print(X_train5.shape, Y_train5.shape)\n",
    "    \n",
    "        X5, Y5 = create_dataset(X_train5, Y_train5, look_back=look_back)\n",
    "        #print(X5.shape, Y5.shape)\n",
    "    \n",
    "        X_all5 = np.append(X_all5, X5, axis=0)\n",
    "        Y_all5 = np.append(Y_all5, Y5, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42049\n"
     ]
    }
   ],
   "source": [
    "print(len(X_all5)//64*64+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all5 = X_all5[1:43457]\n",
    "Y_all5 = Y_all5[1:43457]\n",
    "\n",
    "Xtrain = np.append(Xtrain, X_all5, axis=0)\n",
    "Ytrain = np.append(Ytrain, Y_all5, axis=0)\n",
    "\n",
    "#collections.Counter(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12993 102209\n"
     ]
    }
   ],
   "source": [
    "print(len(X_all)//64*64 + 1, len(X_Test1)//64*64 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XAlltest = X_Test[1:622081]\n",
    "#YAlltest = Y_Test[1:622081]\n",
    "\n",
    "XAlltest1 = X_Test1[1:27841]\n",
    "YAlltest1 = Y_Test1[1:27841]\n",
    "\n",
    "Xtrain = X_all[1:35969]\n",
    "Ytrain = Y_all[1:35969]\n",
    "\n",
    "#collections.Counter(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM network.\n",
    "batch_size = 32\n",
    "dropout = 0.5\n",
    "num_epoch = 100\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "weights = {0:1, 1:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\XWANG221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XWANG221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(batch_input_shape=[32, 50, 2..., units=20)`\n",
      "  \n",
      "C:\\Users\\XWANG221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\XWANG221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\XWANG221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 35968 samples, validate on 27840 samples\n",
      "Epoch 1/100\n",
      "35968/35968 [==============================] - 19s 524us/step - loss: 0.5835 - accuracy: 0.6832 - val_loss: 0.5880 - val_accuracy: 0.7031\n",
      "Epoch 2/100\n",
      "35968/35968 [==============================] - 19s 535us/step - loss: 0.4345 - accuracy: 0.8057 - val_loss: 0.5829 - val_accuracy: 0.7338\n",
      "Epoch 3/100\n",
      "35968/35968 [==============================] - 19s 515us/step - loss: 0.3803 - accuracy: 0.8411 - val_loss: 0.5383 - val_accuracy: 0.7571\n",
      "Epoch 4/100\n",
      "35968/35968 [==============================] - 19s 516us/step - loss: 0.3563 - accuracy: 0.8506 - val_loss: 0.5522 - val_accuracy: 0.7688\n",
      "{'val_loss': [0.587972610182632, 0.5828519457212553, 0.5382926730139331, 0.5521831452589611], 'val_accuracy': [0.703125, 0.7338002920150757, 0.7571479678153992, 0.7688218355178833], 'loss': [0.5835399936049435, 0.43450437873283737, 0.3802782566787085, 0.3563428303472088], 'accuracy': [0.6831628, 0.805744, 0.84108096, 0.8505894]}\n",
      "27840/27840 [==============================] - 4s 152us/step\n"
     ]
    }
   ],
   "source": [
    "model_Following5 = Sequential()\n",
    "model_Following5.add(LSTM(output_dim=20, batch_input_shape=[batch_size, look_back, dimof_input]))\n",
    "model_Following5.add(Dropout(dropout))\n",
    "model_Following5.add(Dense(40, activation='relu'))\n",
    "model_Following5.add(Dropout(dropout))\n",
    "model_Following5.add(Dense(dimof_output, init='uniform', activation='sigmoid'))\n",
    "model_Following5.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history91 = model_Following5.fit(\n",
    "    Xtrain, Ytrain,\n",
    "    class_weight=weights,\n",
    "    validation_data=(XAlltest1, YAlltest1),\n",
    "    callbacks=[earlyStopping],\n",
    "    shuffle=True,\n",
    "    nb_epoch=num_epoch, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print(history91.history)\n",
    "\n",
    "Y_predict4 = model_Following5.predict_classes(XAlltest1, verbose=True)\n",
    "\n",
    "a6 = Y_predict4.tolist()\n",
    "a26 = [item[0] for item in a6]\n",
    "b6 = YAlltest1.tolist()\n",
    "#equal_arrays6 = [i for i, (x, y) in enumerate(zip(a26, b6)) if x == y]\n",
    "#acc6 = len(equal_arrays6)/len(a26)\n",
    "#print(acc6)\n",
    "\n",
    "#f = open(\"CutIn9_clean_TestAll_volvo.csv\", \"w\")\n",
    "\n",
    "#for index in range(len(a26)):\n",
    "#    f.write(str(a26[index]) + \",\" + str(b6[index]) + \"\\n\")\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_predict = [index for index, element in enumerate(a26) if element == 1]\n",
    "p = sum((list(t) for t in zip(nums_predict, nums_predict[1:]) if t[0]+1 != t[1]), [])\n",
    "p.insert(0,nums_predict[0])\n",
    "p.append(nums_predict[-1])\n",
    "\n",
    "nums_Y = [index for index, element in enumerate(b6) if element == 1]\n",
    "y = sum((list(t) for t in zip(nums_Y, nums_Y[1:]) if t[0]+1 != t[1]), [])\n",
    "y.insert(0,nums_Y[0])\n",
    "y.append(nums_Y[-1])\n",
    "\n",
    "big=0\n",
    "small=0\n",
    "same=0\n",
    "\n",
    "for i in range(len(y)-1):\n",
    "    if i % 2 == 0:\n",
    "        for j in range(len(p)):\n",
    "            if j % 2 == 0: \n",
    "\n",
    "                if (y[i] == p[j]) and (y[i+1] == p[j+1]):\n",
    "                    same=same+1\n",
    "                    j=j+2\n",
    "                \n",
    "                elif p[j]<=y[i] and p[j+1]>=y[i+1]:\n",
    "                    big=big+1\n",
    "                    j=j+2\n",
    "                        \n",
    "                elif p[j]>=y[i] and p[j+1]<=y[i+1]:\n",
    "                    small=small+1\n",
    "                    j=j+2\n",
    "                    \n",
    "                else:\n",
    "                    j=j+2       \n",
    "        i=i+2    \n",
    "\n",
    "Predict = len(p)/2\n",
    "Y = len(y)/2\n",
    "#fp = Predict-same\n",
    "#fn = Y-same\n",
    "#prec = same/(same+fp)\n",
    "#recall = same/(same+fn)\n",
    "\n",
    "def precision(n):\n",
    "    fp = Predict-n\n",
    "    prec = n/(n+fp)\n",
    "    if prec >=1:\n",
    "        b=1\n",
    "    else:\n",
    "        b=prec\n",
    "    return b\n",
    "\n",
    "def recall(n):\n",
    "    fn = Y-n\n",
    "    rec = n/(n+fn)\n",
    "    if rec >=1:\n",
    "        a=1\n",
    "    else:\n",
    "        a=rec\n",
    "    return a\n",
    "    \n",
    "def conf(f):\n",
    "    conf95 = []\n",
    "    for i in range(len(y)):\n",
    "        if i%2 == 0:\n",
    "            c951=int(y[i]-f*(y[i+1]-y[i]))\n",
    "            conf95.append(c951)\n",
    "            conf95.append(y[i+1])\n",
    "        \n",
    "            c9522=y[i]+f*(y[i+1]-y[i])\n",
    "            if float(c9522).is_integer()==True:\n",
    "                conf95.append(c9522)\n",
    "                conf95.append(y[i+1])\n",
    "            else:\n",
    "                con952 = int(c9522)+1\n",
    "                conf95.append(con952)\n",
    "                conf95.append(y[i+1])\n",
    "        \n",
    "            conf95.append(y[i])\n",
    "            c9533=int(y[i+1]-f*(y[i+1]-y[i]))\n",
    "            if float(c9533).is_integer()==True:\n",
    "                conf95.append(c9533)\n",
    "            else:\n",
    "                c953 = int(c9533)+1\n",
    "                conf95.append(c953)\n",
    "            \n",
    "            conf95.append(y[i])    \n",
    "            c9544=y[i+1]+f*(y[i+1]-y[i])\n",
    "            if float(c9544).is_integer()==True:\n",
    "                conf95.append(c9544)\n",
    "            else:\n",
    "                con954 = int(c9544)+1\n",
    "                conf95.append(con954)\n",
    "        i=i+2\n",
    "    return conf95\n",
    "\n",
    "def result(rangelist):\n",
    "    con95=0\n",
    "    for i in range(len(p)):\n",
    "        if i%2 == 0:\n",
    "            for j in range(len(rangelist)-7):\n",
    "                if j%8==0:\n",
    "                    if (rangelist[j]<=p[i] and p[i+1]<=rangelist[j+1]) or (rangelist[j+2]<=p[i] and p[i+1]<=rangelist[j+3]) or (rangelist[j+4]<=p[i] and p[i+1]<=rangelist[j+5]) or (rangelist[j+6]<=p[i] and p[i+1]<=rangelist[j+7]):       \n",
    "                        con95=con95+1\n",
    "                        break\n",
    "                    else:\n",
    "                        j=j+8\n",
    "            i=i+2\n",
    "    return con95   \n",
    "\n",
    "con95 = result(conf(0.05))\n",
    "con90 = result(conf(0.1))          \n",
    "con85 = result(conf(0.15))            \n",
    "con80 = result(conf(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: 420.0 - True: 422.0\n",
      "big: 204 - precision: 0.4857142857142857 - recall: 0.4834123222748815\n",
      "small: 67 - precision: 0.1595238095238095 - recall: 0.15876777251184834\n",
      "same: 0 - precision: 0.0 - recall: 0.0\n",
      "con95: 94 - precision: 0.22380952380952382 - recall: 0.22274881516587677\n",
      "con90: 117 - precision: 0.2785714285714286 - recall: 0.2772511848341232\n",
      "con85: 143 - precision: 0.3404761904761905 - recall: 0.33886255924170616\n",
      "con80: 154 - precision: 0.36666666666666664 - recall: 0.36492890995260663\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict:\", Predict, \"-\", \"True:\", Y)   \n",
    "print(\"big:\",big, \"-\", \"precision:\", precision(big), \"-\", \"recall:\", recall(big))  \n",
    "print(\"small:\",small, \"-\", \"precision:\", precision(small), \"-\", \"recall:\", recall(small)) \n",
    "print(\"same:\",same, \"-\", \"precision:\", precision(same), \"-\", \"recall:\", recall(same)) \n",
    "print(\"con95:\",con95, \"-\", \"precision:\", precision(con95), \"-\", \"recall:\", recall(con95))  \n",
    "print(\"con90:\",con90, \"-\", \"precision:\", precision(con90), \"-\", \"recall:\", recall(con90)) \n",
    "print(\"con85:\",con85, \"-\", \"precision:\", precision(con85), \"-\", \"recall:\", recall(con85)) \n",
    "print(\"con80:\",con80, \"-\", \"precision:\", precision(con80), \"-\", \"recall:\", recall(con80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
