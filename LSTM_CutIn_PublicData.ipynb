{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import read_csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a 'look back' dataset for sequence to label prediction with Keras.\n",
    "\n",
    "# The LSTM network expects the input data (X) to be provided with a specific\n",
    "# array structure in the form of: [samples, time steps, features].\n",
    "\n",
    "# create_dataset is adapted from\n",
    "# http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "def create_dataset(X, Y, **options):\n",
    "    \"\"\"Convert an array of X, Y values into a dataset matrix for and LSTM\"\"\"\n",
    "    \n",
    "    look_back = options.pop('look_back', None)\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(X) - look_back):\n",
    "        a = X[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(Y[i + look_back - 1])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# Predictions will be based on look_back minutes of data:\n",
    "look_back = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Test1 = glob.glob('../Users/XiaonfengWang/Desktop/TrafficNet/Required/Test_CutIn_Trac/*.csv')\n",
    "\n",
    "X_Test1 = np.empty((1, 50, 21))\n",
    "Y_Test1 = np.empty((1,))\n",
    "\n",
    "for f in range(len(Test1)):\n",
    "    #print(Test1[f].split('/')[-1])\n",
    "  \n",
    "    CutIn_Test1 = pd.read_csv(Test1[f], usecols=['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','CutIn','o1','o2','o3','r1','r2','r3','t1','t2','t3','tt2','tt3','c2','c3']) \n",
    "    \n",
    "    CutIn_Test1.fillna(10000000, inplace=True)\n",
    "    \n",
    "    Y_train_Test1 = np.array(CutIn_Test1['CutIn'].values)\n",
    "    X_train_Test1 = np.array(CutIn_Test1[['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','o1','o2','o3','r1','r2','r3','t1','t2','t3','tt2','tt3','c2','c3']])\n",
    "    \n",
    "    # Get dimensions of input and output\n",
    "    #dimof_output = int(np.max(Y_train) + 1)\n",
    "    dimof_output = 1\n",
    "    dimof_input = X_train_Test1.shape[1]\n",
    "\n",
    "    # Scale/whiten the X data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_Test1 = scaler.fit_transform(X_train_Test1)\n",
    "    #print(len(X_train))\n",
    "    #print(X_train_Test1.shape, Y_train_Test1.shape)\n",
    "    \n",
    "    XTest1, YTest1 = create_dataset(X_train_Test1, Y_train_Test1, look_back=look_back)\n",
    "    #print(XTest1.shape, YTest1.shape)\n",
    "    \n",
    "    X_Test1 = np.append(X_Test1, XTest1, axis=0)\n",
    "    Y_Test1 = np.append(Y_Test1, YTest1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.glob('../Users/XiaonfengWang/Desktop/TrafficNet/Required/Train_CutIn_Trac/*.csv')\n",
    "\n",
    "X_all = np.empty((1, 50, 21))\n",
    "Y_all = np.empty((1,))\n",
    "\n",
    "for j in range(len(path)):\n",
    "    #print(j)\n",
    "    \n",
    "    CutIn = pd.read_csv(path[j], usecols=['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','CutIn','o1','o2','o3','r1','r2','r3','t1','t2','t3','tt2','tt3','c2','c3']) \n",
    "    if CutIn.shape[0] <= 50:\n",
    "        pass\n",
    "    else:\n",
    "        CutIn.fillna(10000000, inplace=True)\n",
    "    \n",
    "        Y_train = np.array(CutIn['CutIn'].values)\n",
    "        X_train = np.array(CutIn[['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','o1','o2','o3','r1','r2','r3','t1','t2','t3','tt2','tt3','c2','c3']])\n",
    "    # Get dimensions of input and output\n",
    "    #dimof_output = int(np.max(Y_train) + 1)\n",
    "        dimof_output = 1\n",
    "        dimof_input = X_train.shape[1]\n",
    "\n",
    "    # Scale/whiten the X data\n",
    "        scaler = StandardScaler()\n",
    "        XXtrain = scaler.fit_transform(X_train)\n",
    "    #print(len(X_train))\n",
    "        #print(XXtrain.shape, Y_train.shape)\n",
    "    \n",
    "        X, Y = create_dataset(XXtrain, Y_train, look_back=look_back)\n",
    "        #print(X.shape, Y.shape)\n",
    "    \n",
    "        X_all = np.append(X_all, X, axis=0)\n",
    "        Y_all = np.append(Y_all, Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12353 1921\n"
     ]
    }
   ],
   "source": [
    "print(len(X_all)//64*64 + 1, len(X_Test1)//64*64 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XAlltest = X_Test[1:622081]\n",
    "#YAlltest = Y_Test[1:622081]\n",
    "\n",
    "XAlltest1 = X_Test1[1:1921]\n",
    "YAlltest1 = Y_Test1[1:1921]\n",
    "\n",
    "Xtrain = X_all[1:12353]\n",
    "Ytrain = Y_all[1:12353]\n",
    "\n",
    "#collections.Counter(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM network.\n",
    "batch_size = 32\n",
    "dropout = 0.5\n",
    "num_epoch = 100\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "weights = {0:1, 1:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain[:-31]\n",
    "Ytrain = Ytrain[:-31]\n",
    "\n",
    "#35969\n",
    "#Xtrain = Xtrain[:-31]\n",
    "#Ytrain = Ytrain[:-31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(batch_input_shape=[32, 50, 2..., units=20)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 12352 samples, validate on 1920 samples\n",
      "Epoch 1/100\n",
      "12352/12352 [==============================] - 33s 3ms/step - loss: 0.6423 - accuracy: 0.6290 - val_loss: 0.6430 - val_accuracy: 0.5688\n",
      "Epoch 2/100\n",
      "12352/12352 [==============================] - 29s 2ms/step - loss: 0.5559 - accuracy: 0.7030 - val_loss: 0.6206 - val_accuracy: 0.6203\n",
      "Epoch 3/100\n",
      "12352/12352 [==============================] - 27s 2ms/step - loss: 0.5136 - accuracy: 0.7425 - val_loss: 0.6209 - val_accuracy: 0.6276\n",
      "{'val_loss': [0.6430144379536311, 0.6206184106568495, 0.6208789780735969], 'val_accuracy': [0.5687500238418579, 0.620312511920929, 0.6276041865348816], 'loss': [0.6423279436141098, 0.5559470231977769, 0.5136064690166187], 'accuracy': [0.628967, 0.70296305, 0.74247086]}\n",
      "1920/1920 [==============================] - 2s 853us/step\n"
     ]
    }
   ],
   "source": [
    "model_CutIn91 = Sequential()\n",
    "model_CutIn91.add(LSTM(output_dim=20, batch_input_shape=[batch_size, look_back, dimof_input]))\n",
    "model_CutIn91.add(Dropout(dropout))\n",
    "model_CutIn91.add(Dense(30, activation='relu'))\n",
    "model_CutIn91.add(Dropout(dropout))\n",
    "model_CutIn91.add(Dense(dimof_output, init='uniform', activation='sigmoid'))\n",
    "model_CutIn91.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history91 = model_CutIn91.fit(\n",
    "    Xtrain, Ytrain,\n",
    "    class_weight=weights,\n",
    "    validation_data=(XAlltest1, YAlltest1),\n",
    "    callbacks=[earlyStopping],\n",
    "    shuffle=True,\n",
    "    nb_epoch=num_epoch, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print(history91.history)\n",
    "\n",
    "Y_predict4 = model_CutIn91.predict_classes(XAlltest1, verbose=True)\n",
    "\n",
    "a6 = Y_predict4.tolist()\n",
    "a26 = [item[0] for item in a6]\n",
    "b6 = YAlltest1.tolist()\n",
    "#equal_arrays6 = [i for i, (x, y) in enumerate(zip(a26, b6)) if x == y]\n",
    "#acc6 = len(equal_arrays6)/len(a26)\n",
    "#print(acc6)\n",
    "\n",
    "#f = open(\"CutIn9_clean_TestAll_volvo.csv\", \"w\")\n",
    "\n",
    "#for index in range(len(a26)):\n",
    "#    f.write(str(a26[index]) + \",\" + str(b6[index]) + \"\\n\")\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_predict = [index for index, element in enumerate(a26) if element == 1]\n",
    "p = sum((list(t) for t in zip(nums_predict, nums_predict[1:]) if t[0]+1 != t[1]), [])\n",
    "p.insert(0,nums_predict[0])\n",
    "p.append(nums_predict[-1])\n",
    "\n",
    "nums_Y = [index for index, element in enumerate(b6) if element == 1]\n",
    "y = sum((list(t) for t in zip(nums_Y, nums_Y[1:]) if t[0]+1 != t[1]), [])\n",
    "y.insert(0,nums_Y[0])\n",
    "y.append(nums_Y[-1])\n",
    "\n",
    "big=0\n",
    "small=0\n",
    "same=0\n",
    "\n",
    "for i in range(len(y)-1):\n",
    "    if i % 2 == 0:\n",
    "        for j in range(len(p)):\n",
    "            if j % 2 == 0: \n",
    "\n",
    "                if (y[i] == p[j]) and (y[i+1] == p[j+1]):\n",
    "                    same=same+1\n",
    "                    j=j+2\n",
    "                \n",
    "                elif p[j]<=y[i] and p[j+1]>=y[i+1]:\n",
    "                    big=big+1\n",
    "                    j=j+2\n",
    "                        \n",
    "                elif p[j]>=y[i] and p[j+1]<=y[i+1]:\n",
    "                    small=small+1\n",
    "                    j=j+2\n",
    "                    \n",
    "                else:\n",
    "                    j=j+2       \n",
    "        i=i+2    \n",
    "\n",
    "Predict = len(p)/2\n",
    "Y = len(y)/2\n",
    "#fp = Predict-same\n",
    "#fn = Y-same\n",
    "#prec = same/(same+fp)\n",
    "#recall = same/(same+fn)\n",
    "\n",
    "def precision(n):\n",
    "    fp = Predict-n\n",
    "    prec = n/(n+fp)\n",
    "    return prec\n",
    "\n",
    "def recall(n):\n",
    "    fn = Y-n\n",
    "    rec = n/(n+fn)\n",
    "    return rec\n",
    "    \n",
    "def conf(f):\n",
    "    conf95 = []\n",
    "    for i in range(len(y)):\n",
    "        if i%2 == 0:\n",
    "            c951=int(y[i]-f*(y[i+1]-y[i]))\n",
    "            conf95.append(c951)\n",
    "            conf95.append(y[i+1])\n",
    "        \n",
    "            c9522=y[i]+f*(y[i+1]-y[i])\n",
    "            if float(c9522).is_integer()==True:\n",
    "                conf95.append(c9522)\n",
    "                conf95.append(y[i+1])\n",
    "            else:\n",
    "                con952 = int(c9522)+1\n",
    "                conf95.append(con952)\n",
    "                conf95.append(y[i+1])\n",
    "        \n",
    "            conf95.append(y[i])\n",
    "            c9533=int(y[i+1]-f*(y[i+1]-y[i]))\n",
    "            if float(c9533).is_integer()==True:\n",
    "                conf95.append(c9533)\n",
    "            else:\n",
    "                c953 = int(c9533)+1\n",
    "                conf95.append(c953)\n",
    "            \n",
    "            conf95.append(y[i])    \n",
    "            c9544=y[i+1]+f*(y[i+1]-y[i])\n",
    "            if float(c9544).is_integer()==True:\n",
    "                conf95.append(c9544)\n",
    "            else:\n",
    "                con954 = int(c9544)+1\n",
    "                conf95.append(con954)\n",
    "        i=i+2\n",
    "    return conf95\n",
    "\n",
    "def result(rangelist):\n",
    "    con95=0\n",
    "    for i in range(len(p)):\n",
    "        if i%2 == 0:\n",
    "            for j in range(len(rangelist)-7):\n",
    "                if j%8==0:\n",
    "                    if (rangelist[j]<=p[i] and p[i+1]<=rangelist[j+1]) or (rangelist[j+2]<=p[i] and p[i+1]<=rangelist[j+3]) or (rangelist[j+4]<=p[i] and p[i+1]<=rangelist[j+5]) or (rangelist[j+6]<=p[i] and p[i+1]<=rangelist[j+7]):       \n",
    "                        con95=con95+1\n",
    "                        j=j+8\n",
    "                    else:\n",
    "                        j=j+8\n",
    "            i=i+2\n",
    "    return con95   \n",
    "    \n",
    "con95 = result(conf(0.05))\n",
    "con90 = result(conf(0.1))          \n",
    "con85 = result(conf(0.15))            \n",
    "con80 = result(conf(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: 62.0 - True: 46.0\n",
      "big: 20 - precision: 0.3225806451612903 - recall: 0.43478260869565216\n",
      "small: 10 - precision: 0.16129032258064516 - recall: 0.21739130434782608\n",
      "same: 4 - precision: 0.06451612903225806 - recall: 0.08695652173913043\n",
      "con95: 21 - precision: 0.3387096774193548 - recall: 0.45652173913043476\n",
      "con90: 24 - precision: 0.3870967741935484 - recall: 0.5217391304347826\n",
      "con85: 29 - precision: 0.46774193548387094 - recall: 0.6304347826086957\n",
      "con80: 32 - precision: 0.5161290322580645 - recall: 0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict:\", Predict, \"-\", \"True:\", Y)   \n",
    "print(\"big:\",big, \"-\", \"precision:\", precision(big), \"-\", \"recall:\", recall(big))  \n",
    "print(\"small:\",small, \"-\", \"precision:\", precision(small), \"-\", \"recall:\", recall(small)) \n",
    "print(\"same:\",same, \"-\", \"precision:\", precision(same), \"-\", \"recall:\", recall(same)) \n",
    "print(\"con95:\",con95, \"-\", \"precision:\", precision(con95), \"-\", \"recall:\", recall(con95))  \n",
    "print(\"con90:\",con90, \"-\", \"precision:\", precision(con90), \"-\", \"recall:\", recall(con90)) \n",
    "print(\"con85:\",con85, \"-\", \"precision:\", precision(con85), \"-\", \"recall:\", recall(con85)) \n",
    "print(\"con80:\",con80, \"-\", \"precision:\", precision(con80), \"-\", \"recall:\", recall(con80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#model_Flow1.save(\"TrafficNetToVolvo_FlowMaskingSparse-1.h5\")\n",
    "model_CutIn91.save(\"CutIn_Net_precision_recall.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.glob('../TrafficNet/VolvoData/Test_2019w26_CPUload_Kiel_Amsterdam/*.csv')\n",
    "\n",
    "XPP_volvo = np.empty((1, 50, 21))\n",
    "YPP_volvo = np.empty((1,))\n",
    "\n",
    "for j in range(len(path)):\n",
    "    #print(j)\n",
    "    \n",
    "    volvo = pd.read_csv(path[j], usecols=['Lat','Long','YawRate','Velocity','Acceleration','PositionInLane','InReverse','Id1','Id2','Id3','PosLgt1','PosLgt2','PosLgt3','PosLat1','PosLat2','PosLat3','Type2','Type3','Lane2','Lane3','CutIn'])\n",
    "    if volvo.shape[0] <= 50:\n",
    "        pass\n",
    "    else:\n",
    "        volvo['PositionInLaneRight'] = 2.5 - volvo['PositionInLane']\n",
    "        volvo.fillna(10000000, inplace=True)\n",
    "    \n",
    "        Yvolvo = np.array(volvo['CutIn'].values)\n",
    "        Xvolvo = np.array(volvo[['Lat','Long','YawRate','Velocity','Acceleration','PositionInLane','PositionInLaneRight','InReverse','Id1','Id2','Id3','PosLgt1','PosLgt2','PosLgt3','PosLat1','PosLat2','PosLat3','Type2','Type3','Lane2','Lane3']])\n",
    "\n",
    "    # Scale/whiten the X data\n",
    "        scaler = StandardScaler()\n",
    "        X_volvo = scaler.fit_transform(Xvolvo)\n",
    "        XP_volvo, YP_volvo = create_dataset(X_volvo, Yvolvo, look_back=look_back)\n",
    "        #print(X5.shape, Y5.shape)\n",
    "    \n",
    "        XPP_volvo = np.append(XPP_volvo, XP_volvo, axis=0)\n",
    "        YPP_volvo = np.append(YPP_volvo, YP_volvo, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5377\n"
     ]
    }
   ],
   "source": [
    "print(len(YPP_volvo)//64*64+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPP_volvo = XPP_volvo[1:5377]\n",
    "YPP_volvo = YPP_volvo[1:5377]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5376/5376 [==============================] - 4s 682us/step\n"
     ]
    }
   ],
   "source": [
    "Y_predict_volvo = model_CutIn91.predict_classes(XPP_volvo, verbose=True)\n",
    "\n",
    "a6 = Y_predict_volvo.tolist()\n",
    "a26 = [item[0] for item in a6]\n",
    "b6 = YPP_volvo.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: 145.0 - True: 96.0\n",
      "big: 25 - precision: 0.1724137931034483 - recall: 0.2604166666666667\n",
      "small: 33 - precision: 0.22758620689655173 - recall: 0.34375\n",
      "-\n",
      "same: 0 - precision: 0.0 - recall: 0.0\n",
      "con95: 40 - precision: 0.27586206896551724 - recall: 0.4166666666666667\n",
      "con90: 43 - precision: 0.296551724137931 - recall: 0.4479166666666667\n",
      "con85: 47 - precision: 0.32413793103448274 - recall: 0.4895833333333333\n",
      "con80: 51 - precision: 0.35172413793103446 - recall: 0.53125\n"
     ]
    }
   ],
   "source": [
    "# Test_2019w26_CPUload_Kiel_Amsterdam-0011\n",
    "print(\"Predict:\", Predict, \"-\", \"True:\", Y)   \n",
    "print(\"big:\",big, \"-\", \"precision:\", precision(big), \"-\", \"recall:\", recall(big))  \n",
    "print(\"small:\",small, \"-\", \"precision:\", precision(small), \"-\", \"recall:\", recall(small)) \n",
    "print(\"-\")\n",
    "print(\"same:\",same, \"-\", \"precision:\", precision(same), \"-\", \"recall:\", recall(same)) \n",
    "print(\"con95:\",con95, \"-\", \"precision:\", precision(con95), \"-\", \"recall:\", recall(con95))  \n",
    "print(\"con90:\",con90, \"-\", \"precision:\", precision(con90), \"-\", \"recall:\", recall(con90)) \n",
    "print(\"con85:\",con85, \"-\", \"precision:\", precision(con85), \"-\", \"recall:\", recall(con85)) \n",
    "print(\"con80:\",con80, \"-\", \"precision:\", precision(con80), \"-\", \"recall:\", recall(con80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
