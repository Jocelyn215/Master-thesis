{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import read_csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a 'look back' dataset for sequence to label prediction with Keras.\n",
    "\n",
    "# The LSTM network expects the input data (X) to be provided with a specific\n",
    "# array structure in the form of: [samples, time steps, features].\n",
    "\n",
    "def create_dataset(X, Y, **options):\n",
    "    \"\"\"Convert an array of X, Y values into a dataset matrix for and LSTM\"\"\"\n",
    "    \n",
    "    look_back = options.pop('look_back', None)\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(X) - look_back):\n",
    "        a = X[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(Y[i + look_back - 1])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# Predictions will be based on look_back minutes of data:\n",
    "look_back = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Test_path = glob.glob('../Users/XiaonfengWang/Desktop/Test_CutIn_Trac/*.csv')\n",
    "\n",
    "X_TestData = np.empty((1, 50, 21))\n",
    "Y_TestData = np.empty((1,))\n",
    "\n",
    "for f in range(len(Test_path)):\n",
    "  \n",
    "    CutIn_Test = pd.read_csv(Test_path[f], usecols=['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','CutIn','o1','o2','o3','r1','r2','r3','t1','t2','t3','tt2','tt3','c2','c3']) \n",
    "    \n",
    "    CutIn_Test.fillna(10000000, inplace=True)\n",
    "    \n",
    "    Y_train_Test = np.array(CutIn_Test['CutIn'].values)\n",
    "    X_train_Test = np.array(CutIn_Test[['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','o1','o2','o3','r1','r2','r3','t1','t2','t3','tt2','tt3','c2','c3']])\n",
    "    \n",
    "    dimof_output = 1\n",
    "    dimof_input = X_train_Test.shape[1]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_Test = scaler.fit_transform(X_train_Test)\n",
    "    \n",
    "    XTest, YTest = create_dataset(X_train_Test, Y_train_Test, look_back=look_back)\n",
    "    \n",
    "    X_TestData = np.append(X_TestData, XTest, axis=0)\n",
    "    Y_TestData = np.append(Y_TestData, YTest, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_path = glob.glob('../Users/XiaonfengWang/Desktop/Train_CutIn_Trac/*.csv')\n",
    "\n",
    "X_all = np.empty((1, 50, 21))\n",
    "Y_all = np.empty((1,))\n",
    "\n",
    "for j in range(len(path)):\n",
    "    \n",
    "    CutIn = pd.read_csv(Train_path[j], usecols=['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','CutIn','o1','o2','o3','r1','r2','r3','t1','t2','t3','tt2','tt3','c2','c3']) \n",
    "    if CutIn.shape[0] <= 50:\n",
    "        pass\n",
    "    else:\n",
    "        CutIn.fillna(10000000, inplace=True)\n",
    "    \n",
    "        Y_train = np.array(CutIn['CutIn'].values)\n",
    "        X_train = np.array(CutIn[['LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading','o1','o2','o3','r1','r2','r3','t1','t2','t3','tt2','tt3','c2','c3']])\n",
    "\n",
    "        dimof_output = 1\n",
    "        dimof_input = X_train.shape[1]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        XXtrain = scaler.fit_transform(X_train)\n",
    "    \n",
    "        X, Y = create_dataset(XXtrain, Y_train, look_back=look_back)\n",
    "    \n",
    "        X_all = np.append(X_all, X, axis=0)\n",
    "        Y_all = np.append(Y_all, Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These sizes need to be divisible by 32 and remove the first randomly created matrix.\n",
    "Train_size = len(X_all)//64*64 + 1\n",
    "Test_size = len(X_TestData)//64*64 + 1\n",
    "\n",
    "Xtest = X_TestData[1:Test_size]\n",
    "Ytest = Y_TestData[1:Test_size]\n",
    "\n",
    "Xtrain = X_all[1:Train_size]\n",
    "Ytrain = Y_all[1:Train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM network.\n",
    "batch_size = 32\n",
    "dropout = 0.5\n",
    "num_epoch = 100\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "weights = {0:1, 1:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(batch_input_shape=[32, 50, 2..., units=20)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jocelyn/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 12352 samples, validate on 1920 samples\n",
      "Epoch 1/100\n",
      "12352/12352 [==============================] - 33s 3ms/step - loss: 0.6423 - accuracy: 0.6290 - val_loss: 0.6430 - val_accuracy: 0.5688\n",
      "Epoch 2/100\n",
      "12352/12352 [==============================] - 29s 2ms/step - loss: 0.5559 - accuracy: 0.7030 - val_loss: 0.6206 - val_accuracy: 0.6203\n",
      "Epoch 3/100\n",
      "12352/12352 [==============================] - 27s 2ms/step - loss: 0.5136 - accuracy: 0.7425 - val_loss: 0.6209 - val_accuracy: 0.6276\n",
      "{'val_loss': [0.6430144379536311, 0.6206184106568495, 0.6208789780735969], 'val_accuracy': [0.5687500238418579, 0.620312511920929, 0.6276041865348816], 'loss': [0.6423279436141098, 0.5559470231977769, 0.5136064690166187], 'accuracy': [0.628967, 0.70296305, 0.74247086]}\n",
      "1920/1920 [==============================] - 2s 853us/step\n"
     ]
    }
   ],
   "source": [
    "model_CutIn = Sequential()\n",
    "model_CutIn.add(LSTM(output_dim=20, batch_input_shape=[batch_size, look_back, dimof_input]))\n",
    "model_CutIn.add(Dropout(dropout))\n",
    "model_CutIn.add(Dense(30, activation='relu'))\n",
    "model_CutIn.add(Dropout(dropout))\n",
    "model_CutIn.add(Dense(dimof_output, init='uniform', activation='sigmoid'))\n",
    "model_CutIn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = model_CutIn.fit(\n",
    "    Xtrain, Ytrain,\n",
    "    class_weight=weights,\n",
    "    validation_data=(Xtest, Ytest),\n",
    "    callbacks=[earlyStopping],\n",
    "    shuffle=True,\n",
    "    nb_epoch=num_epoch, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print(history.history)\n",
    "\n",
    "Y_predict = model_CutIn.predict_classes(Xtest, verbose=True)\n",
    "\n",
    "# Add the prediction in a list\n",
    "a6 = Y_predict.tolist()\n",
    "# item[0] of the prediction is the predicted label\n",
    "a26 = [item[0] for item in a6]\n",
    "# the true label\n",
    "b6 = Ytest.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_predict = [index for index, element in enumerate(a26) if element == 1]\n",
    "p = sum((list(t) for t in zip(nums_predict, nums_predict[1:]) if t[0]+1 != t[1]), [])\n",
    "p.insert(0,nums_predict[0])\n",
    "p.append(nums_predict[-1])\n",
    "\n",
    "nums_Y = [index for index, element in enumerate(b6) if element == 1]\n",
    "y = sum((list(t) for t in zip(nums_Y, nums_Y[1:]) if t[0]+1 != t[1]), [])\n",
    "y.insert(0,nums_Y[0])\n",
    "y.append(nums_Y[-1])\n",
    "\n",
    "big=0\n",
    "small=0\n",
    "same=0\n",
    "\n",
    "for i in range(len(y)-1):\n",
    "    if i % 2 == 0:\n",
    "        for j in range(len(p)):\n",
    "            if j % 2 == 0: \n",
    "\n",
    "                if (y[i] == p[j]) and (y[i+1] == p[j+1]):\n",
    "                    same=same+1\n",
    "                    j=j+2\n",
    "                \n",
    "                elif p[j]<=y[i] and p[j+1]>=y[i+1]:\n",
    "                    big=big+1\n",
    "                    j=j+2\n",
    "                        \n",
    "                elif p[j]>=y[i] and p[j+1]<=y[i+1]:\n",
    "                    small=small+1\n",
    "                    j=j+2\n",
    "                    \n",
    "                else:\n",
    "                    j=j+2       \n",
    "        i=i+2    \n",
    "\n",
    "Predict = len(p)/2\n",
    "Y = len(y)/2\n",
    "\n",
    "def precision(n):\n",
    "    fp = Predict-n\n",
    "    prec = n/(n+fp)\n",
    "    return prec\n",
    "\n",
    "def recall(n):\n",
    "    fn = Y-n\n",
    "    rec = n/(n+fn)\n",
    "    return rec\n",
    "    \n",
    "def conf(f):\n",
    "    conf95 = []\n",
    "    for i in range(len(y)):\n",
    "        if i%2 == 0:\n",
    "            c951=int(y[i]-f*(y[i+1]-y[i]))\n",
    "            conf95.append(c951)\n",
    "            conf95.append(y[i+1])\n",
    "        \n",
    "            c9522=y[i]+f*(y[i+1]-y[i])\n",
    "            if float(c9522).is_integer()==True:\n",
    "                conf95.append(c9522)\n",
    "                conf95.append(y[i+1])\n",
    "            else:\n",
    "                con952 = int(c9522)+1\n",
    "                conf95.append(con952)\n",
    "                conf95.append(y[i+1])\n",
    "        \n",
    "            conf95.append(y[i])\n",
    "            c9533=int(y[i+1]-f*(y[i+1]-y[i]))\n",
    "            if float(c9533).is_integer()==True:\n",
    "                conf95.append(c9533)\n",
    "            else:\n",
    "                c953 = int(c9533)+1\n",
    "                conf95.append(c953)\n",
    "            \n",
    "            conf95.append(y[i])    \n",
    "            c9544=y[i+1]+f*(y[i+1]-y[i])\n",
    "            if float(c9544).is_integer()==True:\n",
    "                conf95.append(c9544)\n",
    "            else:\n",
    "                con954 = int(c9544)+1\n",
    "                conf95.append(con954)\n",
    "        i=i+2\n",
    "    return conf95\n",
    "\n",
    "def result(rangelist):\n",
    "    con95=0\n",
    "    for i in range(len(p)):\n",
    "        if i%2 == 0:\n",
    "            for j in range(len(rangelist)-7):\n",
    "                if j%8==0:\n",
    "                    if (rangelist[j]<=p[i] and p[i+1]<=rangelist[j+1]) or (rangelist[j+2]<=p[i] and p[i+1]<=rangelist[j+3]) or (rangelist[j+4]<=p[i] and p[i+1]<=rangelist[j+5]) or (rangelist[j+6]<=p[i] and p[i+1]<=rangelist[j+7]):       \n",
    "                        con95=con95+1\n",
    "                        j=j+8\n",
    "                    else:\n",
    "                        j=j+8\n",
    "            i=i+2\n",
    "    return con95   \n",
    "    \n",
    "con95 = result(conf(0.05))\n",
    "con90 = result(conf(0.1))          \n",
    "con85 = result(conf(0.15))            \n",
    "con80 = result(conf(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: 62.0 - True: 46.0\n",
      "big: 20 - precision: 0.3225806451612903 - recall: 0.43478260869565216\n",
      "small: 10 - precision: 0.16129032258064516 - recall: 0.21739130434782608\n",
      "same: 4 - precision: 0.06451612903225806 - recall: 0.08695652173913043\n",
      "con95: 21 - precision: 0.3387096774193548 - recall: 0.45652173913043476\n",
      "con90: 24 - precision: 0.3870967741935484 - recall: 0.5217391304347826\n",
      "con85: 29 - precision: 0.46774193548387094 - recall: 0.6304347826086957\n",
      "con80: 32 - precision: 0.5161290322580645 - recall: 0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict:\", Predict, \"-\", \"True:\", Y)   \n",
    "print(\"big:\",big, \"-\", \"precision:\", precision(big), \"-\", \"recall:\", recall(big))  \n",
    "print(\"small:\",small, \"-\", \"precision:\", precision(small), \"-\", \"recall:\", recall(small)) \n",
    "print(\"same:\",same, \"-\", \"precision:\", precision(same), \"-\", \"recall:\", recall(same)) \n",
    "print(\"con95:\",con95, \"-\", \"precision:\", precision(con95), \"-\", \"recall:\", recall(con95))  \n",
    "print(\"con90:\",con90, \"-\", \"precision:\", precision(con90), \"-\", \"recall:\", recall(con90)) \n",
    "print(\"con85:\",con85, \"-\", \"precision:\", precision(con85), \"-\", \"recall:\", recall(con85)) \n",
    "print(\"con80:\",con80, \"-\", \"precision:\", precision(con80), \"-\", \"recall:\", recall(con80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
